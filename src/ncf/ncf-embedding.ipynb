{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69c1223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Walk up the directory tree until we find 'src'\n",
    "path = current_dir\n",
    "src_path = None\n",
    "\n",
    "while True:\n",
    "    if os.path.basename(path) == \"src\":\n",
    "        src_path = path\n",
    "        break\n",
    "    parent = os.path.dirname(path)\n",
    "    if parent == path:  # reached filesystem root\n",
    "        break\n",
    "    path = parent\n",
    "\n",
    "# Add src to sys.path if found\n",
    "if src_path and src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "# local imports\n",
    "from utils.ncfdata import NCFData\n",
    "from helpers.ncf_model import NCF\n",
    "from helpers import download_ml1m_dataset\n",
    "from helpers.ranking_metrics import hit, ndcg\n",
    "from utils.load_all_data import load_all_data\n",
    "from utils.ml_to_ncf import preprocess_ml1m_to_ncf_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea9a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_embedding_size(factor_num, epochs=10):\n",
    "    \"\"\"\n",
    "    Train a model with a specific embedding size and return RMSE, HR@10, and NDCG@10.\n",
    "    This is a simplified version for quick evaluation.\n",
    "    \"\"\"\n",
    "    print(f\"  Training with embedding size: {factor_num}...\")\n",
    "    \n",
    "    # Create model with specific embedding size\n",
    "    test_model = NCF(\n",
    "        user_num=user_num,\n",
    "        item_num=item_num,\n",
    "        factor_num=factor_num,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout_rate,\n",
    "        model_name='GMF',\n",
    "        GMF_model=None,\n",
    "        MLP_model=None\n",
    "    )\n",
    "    \n",
    "    if device == 'cuda' and torch.cuda.is_available():\n",
    "        test_model = test_model.cuda()\n",
    "    \n",
    "    # Setup optimizer\n",
    "    test_optimizer = optim.Adam(test_model.parameters(), lr=learning_rate)\n",
    "    test_loss_function = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Train for fewer epochs for speed\n",
    "    best_ndcg = 0.0\n",
    "    best_hr = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        test_model.train()\n",
    "        train_dataset.ng_sample()\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_idx, (user, item, label) in enumerate(train_loader):\n",
    "            if device == 'cuda' and torch.cuda.is_available():\n",
    "                user = user.cuda()\n",
    "                item = item.cuda()\n",
    "                label = label.float().cuda()\n",
    "            else:\n",
    "                user = user\n",
    "                item = item\n",
    "                label = label.float()\n",
    "            \n",
    "            test_optimizer.zero_grad()\n",
    "            prediction = test_model(user, item)\n",
    "            loss = test_loss_function(prediction, label)\n",
    "            loss.backward()\n",
    "            test_optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        # Evaluate periodically\n",
    "        if (epoch + 1) % 5 == 0 or epoch == epochs - 1:\n",
    "            test_model.eval()\n",
    "            \n",
    "            HR, NDCG = evaluate_metrics(test_model, test_loader, top_k, device)\n",
    "            # Track best metrics\n",
    "            if NDCG > best_ndcg:\n",
    "                best_ndcg = NDCG\n",
    "            if HR > best_hr:\n",
    "                best_hr = HR\n",
    "    \n",
    "    print(f\" HR@10: {best_hr:.4f}, NDCG@10: {best_ndcg:.4f}\")\n",
    "    return  best_hr, best_ndcg\n",
    "\n",
    "# Test different embedding sizes\n",
    "embedding_sizes = [8, 16, 32, 64, 128]\n",
    "print(f\"\\nTraining models with different embedding sizes: {embedding_sizes}\")\n",
    "print(\"Note: This may take some time. Using reduced epochs for speed.\")\n",
    "\n",
    "hr_results = []\n",
    "ndcg_results = []\n",
    "\n",
    "for size in embedding_sizes:\n",
    "    hr_val, ndcg_val = train_and_evaluate_embedding_size(size, epochs=10)  # Reduced epochs for speed\n",
    "    hr_results.append(hr_val)\n",
    "    ndcg_results.append(ndcg_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c752036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with subplots for all three metrics\n",
    "fig_embedding, axes = plt.subplots(1, 2, figsize=(18, 5))\n",
    "\n",
    "# Plot 2: HR@10\n",
    "axes[0].plot(embedding_sizes, hr_results, 'g-o', linewidth=2, markersize=8, \n",
    "             markerfacecolor='lightgreen', markeredgewidth=2)\n",
    "axes[0].set_xlabel('Embedding Size', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('HR@10', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('HR@10 vs Embedding Size', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xticks(embedding_sizes)\n",
    "axes[0].set_ylim([min(hr_results) * 0.95, max(hr_results) * 1.05])\n",
    "\n",
    "# Add value labels on points\n",
    "for i, (size, hr) in enumerate(zip(embedding_sizes, hr_results)):\n",
    "    axes[0].annotate(f'{hr:.3f}', (size, hr), textcoords=\"offset points\", \n",
    "                    xytext=(0,10), ha='center', fontsize=9)\n",
    "\n",
    "# Plot 3: NDCG@10\n",
    "axes[1].plot(embedding_sizes, ndcg_results, 'b-o', linewidth=2, markersize=8, \n",
    "             markerfacecolor='lightblue', markeredgewidth=2)\n",
    "axes[1].set_xlabel('Embedding Size', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('NDCG@10', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('NDCG@10 vs Embedding Size', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xticks(embedding_sizes)\n",
    "axes[1].set_ylim([min(ndcg_results) * 0.95, max(ndcg_results) * 1.05])\n",
    "\n",
    "# Add value labels on points\n",
    "for i, (size, ndcg) in enumerate(zip(embedding_sizes, ndcg_results)):\n",
    "    axes[1].annotate(f'{ndcg:.3f}', (size, ndcg), textcoords=\"offset points\", \n",
    "                    xytext=(0,10), ha='center', fontsize=9)\n",
    "\n",
    "plt.suptitle('Figure 4.2: Impact of Embedding Size on Model Performance', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(model_path, 'figure_4.2_embedding_size.png'), dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nâœ“ Figure 4.2 saved to: {os.path.join(model_path, 'figure_4.2_embedding_size.png')}\")\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Embedding Size Impact Summary\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Embedding Size':<15} {'RMSE':<10} {'HR@10':<10} {'NDCG@10':<10}\")\n",
    "print(\"-\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

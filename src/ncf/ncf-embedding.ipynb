{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69c1223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Walk up the directory tree until we find 'src'\n",
    "path = current_dir\n",
    "src_path = None\n",
    "\n",
    "while True:\n",
    "    if os.path.basename(path) == \"src\":\n",
    "        src_path = path\n",
    "        break\n",
    "    parent = os.path.dirname(path)\n",
    "    if parent == path:  # reached filesystem root\n",
    "        break\n",
    "    path = parent\n",
    "\n",
    "# Add src to sys.path if found\n",
    "if src_path and src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# local imports\n",
    "from utils.ncfdata import NCFData\n",
    "from helpers.ncf_model import NCF\n",
    "from helpers import download_ml1m_dataset\n",
    "from helpers.ranking_metrics import hit, ndcg\n",
    "from utils.load_all_data import load_all_data\n",
    "from utils.ml_to_ncf import preprocess_ml1m_to_ncf_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf8a773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Configuration and hyperparameters\n",
    "DATASET = 'ml-1m'\n",
    "\n",
    "DATA_DIR = os.path.join(os.path.dirname(os.getcwd()), '..', 'data')\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "\n",
    "# Model saving directory\n",
    "MODEL_PATH = os.path.join(os.path.dirname(os.getcwd()), '..', 'models')\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)\n",
    "\n",
    "# Hyperparameters\n",
    "LEARNING_RATE = 0.001\n",
    "DROPOUT_RATE = 0.1\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 20\n",
    "TOP_K = 10\n",
    "FACTOR_NUM = 32  # Default embedding size (will be varied in the experiment)\n",
    "NUM_LAYERS = 3\n",
    "NUM_NG = 4\n",
    "TEST_NUM_NG = 99\n",
    "\n",
    "# Determine device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model path for saving figures\n",
    "model_path = MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55deb3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset already exists at /Users/abbas/Documents/Codes/thesis/recommender/src/../data/ml-1m/ratings.dat\n",
      "✓ Training matrix created: 460225 interactions\n"
     ]
    }
   ],
   "source": [
    "# Download and preprocess data\n",
    "ratings_file = download_ml1m_dataset(DATA_DIR)\n",
    "train_rating_path, test_rating_path, test_negative_path, user_num, item_num, train_mat = preprocess_ml1m_to_ncf_format(\n",
    "    ratings_file, data_dir=DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51dcd8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from /Users/abbas/Documents/Codes/thesis/recommender/src/../data/ml-1m.train.rating...\n",
      "✓ Loaded 460225 training pairs\n",
      "  - Users: 6038\n",
      "  - Items: 3533\n"
     ]
    }
   ],
   "source": [
    "# Load all data\n",
    "train_data, test_data, user_num, item_num, train_mat = load_all_data(\n",
    "    train_rating_path, test_negative_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a92b23de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = NCFData(\n",
    "    train_data,\n",
    "    item_num,\n",
    "    train_mat,\n",
    "    num_ng=NUM_NG,\n",
    "    is_training=True\n",
    ")\n",
    "\n",
    "test_dataset = NCFData(\n",
    "    test_data,\n",
    "    item_num,\n",
    "    train_mat,\n",
    "    num_ng=0,  # No negative sampling for testing\n",
    "    is_training=False\n",
    ")\n",
    "\n",
    "train_loader = data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_loader = data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=TEST_NUM_NG + 1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e5aaf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_metrics(model, test_loader, top_k, device='cuda'):\n",
    "    \"\"\"Evaluate model using HR@K and NDCG@K metrics.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    HR_list = []\n",
    "    NDCG_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for user, item, label in test_loader:\n",
    "            # Move data to device\n",
    "            if device == 'cuda' and torch.cuda.is_available():\n",
    "                user = user.cuda()\n",
    "                item = item.cuda()\n",
    "            # else: data stays on CPU, no need to reassign device\n",
    "            \n",
    "            predictions = model(user, item)\n",
    "            _, indices = torch.topk(predictions, top_k)\n",
    "            \n",
    "            # Get the actual item IDs for top-K recommendations\n",
    "            recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
    "            \n",
    "            # Ground truth item is the first one (positive sample)\n",
    "            gt_item = item[0].item()\n",
    "            \n",
    "            HR_list.append(hit(gt_item, recommends))\n",
    "            NDCG_list.append(ndcg(gt_item, recommends))\n",
    "    \n",
    "    try:\n",
    "        mean_HR = np.mean(HR_list)\n",
    "        mean_NDCG = np.mean(NDCG_list)\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating mean: {e}\")\n",
    "        mean_HR = 0\n",
    "        mean_NDCG = 0\n",
    "    \n",
    "    return mean_HR, mean_NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea9a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_embedding_size(factor_num, epochs=10):\n",
    "    \"\"\"\n",
    "    Train a model with a specific embedding size and return HR@10, and NDCG@10.\n",
    "    This is a simplified version for quick evaluation.\n",
    "    \"\"\"\n",
    "    print(f\"  Training with embedding size: {factor_num}...\")\n",
    "    \n",
    "    # Create model with specific embedding size\n",
    "    test_model = NCF(\n",
    "        user_num=user_num,\n",
    "        item_num=item_num,\n",
    "        factor_num=factor_num,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        dropout=DROPOUT_RATE,\n",
    "        model_name='GMF',\n",
    "        GMF_model=None,\n",
    "        MLP_model=None\n",
    "    )\n",
    "    \n",
    "    if device == 'cuda' and torch.cuda.is_available():\n",
    "        test_model = test_model.cuda()\n",
    "    \n",
    "    # Setup optimizer\n",
    "    test_optimizer = optim.Adam(test_model.parameters(), lr=LEARNING_RATE)\n",
    "    test_loss_function = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Train for fewer epochs for speed\n",
    "    best_ndcg = 0.0\n",
    "    best_hr = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        test_model.train()\n",
    "        train_dataset.ng_sample()\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_idx, (user, item, label) in enumerate(train_loader):\n",
    "            if device == 'cuda' and torch.cuda.is_available():\n",
    "                user = user.cuda()\n",
    "                item = item.cuda()\n",
    "                label = label.float().cuda()\n",
    "            else:\n",
    "                user = user\n",
    "                item = item\n",
    "                label = label.float()\n",
    "            \n",
    "            test_optimizer.zero_grad()\n",
    "            prediction = test_model(user, item)\n",
    "            loss = test_loss_function(prediction, label)\n",
    "            loss.backward()\n",
    "            test_optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        # Evaluate periodically\n",
    "        if (epoch + 1) % 5 == 0 or epoch == epochs - 1:\n",
    "            test_model.eval()\n",
    "            \n",
    "            HR, NDCG = evaluate_metrics(test_model, test_loader, TOP_K, device)\n",
    "            # Track best metrics\n",
    "            if NDCG > best_ndcg:\n",
    "                best_ndcg = NDCG\n",
    "            if HR > best_hr:\n",
    "                best_hr = HR\n",
    "    \n",
    "    print(f\" HR@10: {best_hr:.4f}, NDCG@10: {best_ndcg:.4f}\")\n",
    "    return best_hr, best_ndcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f3ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different embedding sizes\n",
    "embedding_sizes = [8, 16, 32, 64, 128]\n",
    "print(f\"\\nTraining models with different embedding sizes: {embedding_sizes}\")\n",
    "print(\"Note: This may take some time. Using reduced epochs for speed.\")\n",
    "\n",
    "hr_results = []\n",
    "ndcg_results = []\n",
    "\n",
    "for size in embedding_sizes:\n",
    "    hr_val, ndcg_val = train_and_evaluate_embedding_size(size, epochs=10)  # Reduced epochs for speed\n",
    "    hr_results.append(hr_val)\n",
    "    ndcg_results.append(ndcg_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c752036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with subplots for all three metrics\n",
    "fig_embedding, axes = plt.subplots(1, 2, figsize=(18, 5))\n",
    "\n",
    "# Plot 1: HR@10\n",
    "axes[0].plot(embedding_sizes, hr_results, 'g-o', linewidth=2, markersize=8, \n",
    "             markerfacecolor='lightgreen', markeredgewidth=2)\n",
    "axes[0].set_xlabel('Embedding Size', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('HR@10', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('HR@10 vs Embedding Size', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xticks(embedding_sizes)\n",
    "if hr_results:\n",
    "    axes[0].set_ylim([min(hr_results) * 0.95, max(hr_results) * 1.05])\n",
    "\n",
    "# Add value labels on points\n",
    "for i, (size, hr) in enumerate(zip(embedding_sizes, hr_results)):\n",
    "    axes[0].annotate(f'{hr:.3f}', (size, hr), textcoords=\"offset points\", \n",
    "                    xytext=(0,10), ha='center', fontsize=9)\n",
    "\n",
    "# Plot 2: NDCG@10\n",
    "axes[1].plot(embedding_sizes, ndcg_results, 'b-o', linewidth=2, markersize=8, \n",
    "             markerfacecolor='lightblue', markeredgewidth=2)\n",
    "axes[1].set_xlabel('Embedding Size', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('NDCG@10', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('NDCG@10 vs Embedding Size', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xticks(embedding_sizes)\n",
    "if ndcg_results:\n",
    "    axes[1].set_ylim([min(ndcg_results) * 0.95, max(ndcg_results) * 1.05])\n",
    "\n",
    "# Add value labels on points\n",
    "for i, (size, ndcg) in enumerate(zip(embedding_sizes, ndcg_results)):\n",
    "    axes[1].annotate(f'{ndcg:.3f}', (size, ndcg), textcoords=\"offset points\", \n",
    "                    xytext=(0,10), ha='center', fontsize=9)\n",
    "\n",
    "plt.suptitle('Figure 4.2: Impact of Embedding Size on Model Performance', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(model_path, 'figure_4.2_embedding_size.png'), dpi=300, bbox_inches='tight')\n",
    "print(f\"\\n✓ Figure 4.2 saved to: {os.path.join(model_path, 'figure_4.2_embedding_size.png')}\")\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Embedding Size Impact Summary\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Embedding Size':<15} {'HR@10':<10} {'NDCG@10':<10}\")\n",
    "print(\"-\" * 70)\n",
    "for size, hr, ndcg in zip(embedding_sizes, hr_results, ndcg_results):\n",
    "    print(f\"{size:<15} {hr:<10.4f} {ndcg:<10.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

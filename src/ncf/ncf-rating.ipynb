{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Collaborative Filtering for Rating Prediction\n",
        "\n",
        "## Motivation\n",
        "\n",
        "The original NCF (He et al., 2017) was designed for **implicit feedback** (binary interactions). \n",
        "\n",
        "For **explicit feedback** (ratings 1-5), we modify:\n",
        "1. **Loss**: BCE → MSE (regression task)\n",
        "2. **Output**: Scaled sigmoid to [1, 5]\n",
        "3. **Data**: Actual ratings, no negative sampling\n",
        "\n",
        "## Models to Compare\n",
        "\n",
        "| Model | Description |\n",
        "|-------|-------------|\n",
        "| **GMF** | Generalized Matrix Factorization (linear) |\n",
        "| **MLP** | Multi-Layer Perceptron (non-linear) |\n",
        "| **NeuMF-end** | GMF + MLP trained end-to-end |\n",
        "| **NeuMF-pre** | GMF + MLP with pre-trained initialization |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Add src to path\n",
        "current_dir = os.getcwd()\n",
        "path = current_dir\n",
        "while True:\n",
        "    if os.path.basename(path) == \"src\":\n",
        "        if path not in sys.path:\n",
        "            sys.path.insert(0, path)\n",
        "        break\n",
        "    parent = os.path.dirname(path)\n",
        "    if parent == path:\n",
        "        break\n",
        "    path = parent\n",
        "\n",
        "from helpers import download_ml1m_dataset\n",
        "\n",
        "# Reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths\n",
        "DATA_DIR = os.path.join(os.path.dirname(os.getcwd()), '..', 'data')\n",
        "MODEL_PATH = os.path.join(os.path.dirname(os.getcwd()), '..', 'models')\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_PATH, exist_ok=True)\n",
        "\n",
        "# Hyperparameters\n",
        "LEARNING_RATE = 0.001\n",
        "DROPOUT_RATE = 0.2\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 30\n",
        "FACTOR_NUM = 32\n",
        "NUM_LAYERS = 3\n",
        "EARLY_STOPPING_PATIENCE = 5\n",
        "TEST_RATIO = 0.2\n",
        "\n",
        "RATING_MIN = 1.0\n",
        "RATING_MAX = 5.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ratings_file = download_ml1m_dataset(DATA_DIR)\n",
        "\n",
        "ratings_df = pd.read_csv(\n",
        "    ratings_file,\n",
        "    sep='::',\n",
        "    engine='python',\n",
        "    names=['user_id', 'item_id', 'rating', 'timestamp'],\n",
        "    encoding='latin-1'\n",
        ")\n",
        "\n",
        "# Re-index\n",
        "user_ids = ratings_df['user_id'].unique()\n",
        "item_ids = ratings_df['item_id'].unique()\n",
        "user_to_idx = {uid: idx for idx, uid in enumerate(user_ids)}\n",
        "item_to_idx = {iid: idx for idx, iid in enumerate(item_ids)}\n",
        "ratings_df['user_idx'] = ratings_df['user_id'].map(user_to_idx)\n",
        "ratings_df['item_idx'] = ratings_df['item_id'].map(item_to_idx)\n",
        "\n",
        "num_users = len(user_ids)\n",
        "num_items = len(item_ids)\n",
        "\n",
        "print(f\"Users: {num_users}, Items: {num_items}, Ratings: {len(ratings_df):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/Test split\n",
        "train_df, test_df = train_test_split(ratings_df, test_size=TEST_RATIO, random_state=42)\n",
        "print(f\"Train: {len(train_df):,}, Test: {len(test_df):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RatingDataset(data.Dataset):\n",
        "    \"\"\"Dataset for explicit rating prediction (no negative sampling).\"\"\"\n",
        "    \n",
        "    def __init__(self, df):\n",
        "        self.users = torch.LongTensor(df['user_idx'].values)\n",
        "        self.items = torch.LongTensor(df['item_idx'].values)\n",
        "        self.ratings = torch.FloatTensor(df['rating'].values)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.ratings)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
        "\n",
        "\n",
        "train_dataset = RatingDataset(train_df)\n",
        "test_dataset = RatingDataset(test_df)\n",
        "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: NCF Model for Rating Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NCFRating(nn.Module):\n",
        "    \"\"\"\n",
        "    NCF model adapted for rating prediction.\n",
        "    \n",
        "    Supports: 'GMF', 'MLP', 'NeuMF-end', 'NeuMF-pre'\n",
        "    Output: Scaled sigmoid → [rating_min, rating_max]\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, num_users, num_items, factor_num, num_layers,\n",
        "                 dropout, model_name='NeuMF-end', rating_min=1.0, rating_max=5.0,\n",
        "                 GMF_model=None, MLP_model=None):\n",
        "        super(NCFRating, self).__init__()\n",
        "        \n",
        "        self.model_name = model_name\n",
        "        self.dropout = dropout\n",
        "        self.rating_min = rating_min\n",
        "        self.rating_max = rating_max\n",
        "        self.GMF_model = GMF_model\n",
        "        self.MLP_model = MLP_model\n",
        "        \n",
        "        # GMF Embeddings\n",
        "        if model_name != 'MLP':\n",
        "            self.embed_user_GMF = nn.Embedding(num_users, factor_num)\n",
        "            self.embed_item_GMF = nn.Embedding(num_items, factor_num)\n",
        "        \n",
        "        # MLP Embeddings\n",
        "        if model_name != 'GMF':\n",
        "            mlp_embed_dim = factor_num * (2 ** (num_layers - 1))\n",
        "            self.embed_user_MLP = nn.Embedding(num_users, mlp_embed_dim)\n",
        "            self.embed_item_MLP = nn.Embedding(num_items, mlp_embed_dim)\n",
        "            \n",
        "            # MLP Layers\n",
        "            layers = []\n",
        "            for i in range(num_layers):\n",
        "                input_size = factor_num * (2 ** (num_layers - i))\n",
        "                layers.append(nn.Dropout(p=dropout))\n",
        "                layers.append(nn.Linear(input_size, input_size // 2))\n",
        "                layers.append(nn.ReLU())\n",
        "            self.MLP_layers = nn.Sequential(*layers)\n",
        "        \n",
        "        # Prediction Layer\n",
        "        if model_name in ['MLP', 'GMF']:\n",
        "            predict_size = factor_num\n",
        "        else:\n",
        "            predict_size = factor_num * 2\n",
        "        \n",
        "        self.predict_layer = nn.Linear(predict_size, 1)\n",
        "        self._init_weights()\n",
        "    \n",
        "    def _init_weights(self):\n",
        "        if self.model_name != 'NeuMF-pre':\n",
        "            # Random initialization\n",
        "            for name, param in self.named_parameters():\n",
        "                if 'embed' in name:\n",
        "                    nn.init.normal_(param, std=0.01)\n",
        "                elif 'weight' in name:\n",
        "                    nn.init.xavier_uniform_(param)\n",
        "                elif 'bias' in name:\n",
        "                    nn.init.zeros_(param)\n",
        "        else:\n",
        "            # Pre-trained initialization from GMF and MLP\n",
        "            self.embed_user_GMF.weight.data.copy_(self.GMF_model.embed_user_GMF.weight)\n",
        "            self.embed_item_GMF.weight.data.copy_(self.GMF_model.embed_item_GMF.weight)\n",
        "            self.embed_user_MLP.weight.data.copy_(self.MLP_model.embed_user_MLP.weight)\n",
        "            self.embed_item_MLP.weight.data.copy_(self.MLP_model.embed_item_MLP.weight)\n",
        "            \n",
        "            for (m1, m2) in zip(self.MLP_layers, self.MLP_model.MLP_layers):\n",
        "                if isinstance(m1, nn.Linear) and isinstance(m2, nn.Linear):\n",
        "                    m1.weight.data.copy_(m2.weight)\n",
        "                    m1.bias.data.copy_(m2.bias)\n",
        "            \n",
        "            # Combine prediction weights\n",
        "            predict_weight = torch.cat([\n",
        "                self.GMF_model.predict_layer.weight,\n",
        "                self.MLP_model.predict_layer.weight\n",
        "            ], dim=1)\n",
        "            predict_bias = (self.GMF_model.predict_layer.bias + \n",
        "                           self.MLP_model.predict_layer.bias) / 2\n",
        "            \n",
        "            self.predict_layer.weight.data.copy_(0.5 * predict_weight)\n",
        "            self.predict_layer.bias.data.copy_(predict_bias)\n",
        "    \n",
        "    def forward(self, user, item):\n",
        "        # GMF path\n",
        "        if self.model_name != 'MLP':\n",
        "            user_gmf = self.embed_user_GMF(user)\n",
        "            item_gmf = self.embed_item_GMF(item)\n",
        "            output_gmf = user_gmf * item_gmf\n",
        "        \n",
        "        # MLP path\n",
        "        if self.model_name != 'GMF':\n",
        "            user_mlp = self.embed_user_MLP(user)\n",
        "            item_mlp = self.embed_item_MLP(item)\n",
        "            interaction = torch.cat([user_mlp, item_mlp], dim=-1)\n",
        "            output_mlp = self.MLP_layers(interaction)\n",
        "        \n",
        "        # Combine\n",
        "        if self.model_name == 'GMF':\n",
        "            concat = output_gmf\n",
        "        elif self.model_name == 'MLP':\n",
        "            concat = output_mlp\n",
        "        else:\n",
        "            concat = torch.cat([output_gmf, output_mlp], dim=-1)\n",
        "        \n",
        "        # Predict and scale to rating range\n",
        "        logits = self.predict_layer(concat).view(-1)\n",
        "        rating_range = self.rating_max - self.rating_min\n",
        "        return torch.sigmoid(logits) * rating_range + self.rating_min"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Evaluation and Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, device):\n",
        "    \"\"\"Compute RMSE and MAE.\"\"\"\n",
        "    model.eval()\n",
        "    preds, actuals = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for user, item, rating in data_loader:\n",
        "            user, item = user.to(device), item.to(device)\n",
        "            pred = model(user, item)\n",
        "            preds.extend(pred.cpu().numpy())\n",
        "            actuals.extend(rating.numpy())\n",
        "    \n",
        "    preds, actuals = np.array(preds), np.array(actuals)\n",
        "    rmse = np.sqrt(np.mean((preds - actuals) ** 2))\n",
        "    mae = np.mean(np.abs(preds - actuals))\n",
        "    return rmse, mae\n",
        "\n",
        "\n",
        "def train_model(model, model_name, train_loader, test_loader, \n",
        "                epochs, lr, patience, device, save_path):\n",
        "    \"\"\"Train a single model and return history.\"\"\"\n",
        "    model = model.to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    best_rmse = float('inf')\n",
        "    patience_counter = 0\n",
        "    history = {'train_loss': [], 'test_rmse': [], 'test_mae': []}\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        start = time.time()\n",
        "        \n",
        "        for user, item, rating in train_loader:\n",
        "            user, item, rating = user.to(device), item.to(device), rating.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(user, item)\n",
        "            loss = criterion(pred, rating)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(rating)\n",
        "        \n",
        "        avg_loss = total_loss / len(train_loader.dataset)\n",
        "        test_rmse, test_mae = evaluate(model, test_loader, device)\n",
        "        elapsed = time.time() - start\n",
        "        \n",
        "        history['train_loss'].append(avg_loss)\n",
        "        history['test_rmse'].append(test_rmse)\n",
        "        history['test_mae'].append(test_mae)\n",
        "        \n",
        "        if test_rmse < best_rmse:\n",
        "            best_rmse = test_rmse\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            marker = \" *\"\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            marker = \"\"\n",
        "        \n",
        "        print(f\"Epoch {epoch+1:02d} | Loss: {avg_loss:.4f} | RMSE: {test_rmse:.4f} | \"\n",
        "              f\"MAE: {test_mae:.4f} | {elapsed:.1f}s{marker}\")\n",
        "        \n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "    \n",
        "    # Load best weights\n",
        "    model.load_state_dict(torch.load(save_path))\n",
        "    return model, history, best_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 7: Train GMF (Generalized Matrix Factorization)\n",
        "\n",
        "**GMF** uses element-wise product of user and item embeddings (linear interaction)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gmf_model = NCFRating(\n",
        "    num_users=num_users, num_items=num_items,\n",
        "    factor_num=FACTOR_NUM, num_layers=NUM_LAYERS,\n",
        "    dropout=DROPOUT_RATE, model_name='GMF',\n",
        "    rating_min=RATING_MIN, rating_max=RATING_MAX\n",
        ")\n",
        "\n",
        "gmf_model, gmf_history, gmf_best = train_model(\n",
        "    gmf_model, 'GMF', train_loader, test_loader,\n",
        "    EPOCHS, LEARNING_RATE, EARLY_STOPPING_PATIENCE, device,\n",
        "    os.path.join(MODEL_PATH, 'GMF-Rating.pth')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 8: Train MLP (Multi-Layer Perceptron)\n",
        "\n",
        "**MLP** uses a deep neural network for non-linear user-item interactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp_model = NCFRating(\n",
        "    num_users=num_users, num_items=num_items,\n",
        "    factor_num=FACTOR_NUM, num_layers=NUM_LAYERS,\n",
        "    dropout=DROPOUT_RATE, model_name='MLP',\n",
        "    rating_min=RATING_MIN, rating_max=RATING_MAX\n",
        ")\n",
        "\n",
        "mlp_model, mlp_history, mlp_best = train_model(\n",
        "    mlp_model, 'MLP', train_loader, test_loader,\n",
        "    EPOCHS, LEARNING_RATE, EARLY_STOPPING_PATIENCE, device,\n",
        "    os.path.join(MODEL_PATH, 'MLP-Rating.pth')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 9: Train NeuMF-end (End-to-End)\n",
        "\n",
        "**NeuMF-end** combines GMF and MLP paths, trained from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neumf_end_model = NCFRating(\n",
        "    num_users=num_users, num_items=num_items,\n",
        "    factor_num=FACTOR_NUM, num_layers=NUM_LAYERS,\n",
        "    dropout=DROPOUT_RATE, model_name='NeuMF-end',\n",
        "    rating_min=RATING_MIN, rating_max=RATING_MAX\n",
        ")\n",
        "\n",
        "neumf_end_model, neumf_end_history, neumf_end_best = train_model(\n",
        "    neumf_end_model, 'NeuMF-end', train_loader, test_loader,\n",
        "    EPOCHS, LEARNING_RATE, EARLY_STOPPING_PATIENCE, device,\n",
        "    os.path.join(MODEL_PATH, 'NeuMF-end-Rating.pth')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 10: Train NeuMF-pre (Pre-trained Initialization)\n",
        "\n",
        "**NeuMF-pre** initializes GMF and MLP paths with pre-trained weights, then fine-tunes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neumf_pre_model = NCFRating(\n",
        "    num_users=num_users, num_items=num_items,\n",
        "    factor_num=FACTOR_NUM, num_layers=NUM_LAYERS,\n",
        "    dropout=DROPOUT_RATE, model_name='NeuMF-pre',\n",
        "    rating_min=RATING_MIN, rating_max=RATING_MAX,\n",
        "    GMF_model=gmf_model,  # Pre-trained GMF\n",
        "    MLP_model=mlp_model   # Pre-trained MLP\n",
        ")\n",
        "\n",
        "neumf_pre_model, neumf_pre_history, neumf_pre_best = train_model(\n",
        "    neumf_pre_model, 'NeuMF-pre', train_loader, test_loader,\n",
        "    EPOCHS, LEARNING_RATE, EARLY_STOPPING_PATIENCE, device,\n",
        "    os.path.join(MODEL_PATH, 'NeuMF-pre-Rating.pth')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 11: Comparative Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary table\n",
        "results = {\n",
        "    'GMF': gmf_best,\n",
        "    'MLP': mlp_best,\n",
        "    'NeuMF-end': neumf_end_best,\n",
        "    'NeuMF-pre': neumf_pre_best\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"COMPARATIVE RESULTS (Best RMSE)\")\n",
        "print(\"=\"*50)\n",
        "for name, rmse in results.items():\n",
        "    print(f\"{name:12s} | RMSE: {rmse:.4f}\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "best_model = min(results, key=results.get)\n",
        "print(f\"\\nBest Model: {best_model} (RMSE: {results[best_model]:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "histories = [\n",
        "    ('GMF', gmf_history),\n",
        "    ('MLP', mlp_history),\n",
        "    ('NeuMF-end', neumf_end_history),\n",
        "    ('NeuMF-pre', neumf_pre_history)\n",
        "]\n",
        "\n",
        "for ax, (name, hist) in zip(axes.flat, histories):\n",
        "    ax.plot(hist['test_rmse'], 'r-', label='RMSE')\n",
        "    ax.plot(hist['test_mae'], 'b-', label='MAE')\n",
        "    ax.set_title(f'{name}')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Error')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(MODEL_PATH, 'ncf_rating_comparison.png'), dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### Key Modifications for Rating Prediction\n",
        "\n",
        "| Original NCF | Rating NCF |\n",
        "|--------------|------------|\n",
        "| BCEWithLogitsLoss | MSELoss |\n",
        "| Binary labels (0/1) | Actual ratings (1-5) |\n",
        "| Negative sampling | No negative sampling |\n",
        "| HR@K, NDCG@K | RMSE, MAE |\n",
        "\n",
        "### References\n",
        "\n",
        "- He, X., et al. (2017). Neural Collaborative Filtering. WWW'17."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
